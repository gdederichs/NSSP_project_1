{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb3e06b-bfdb-469e-9b60-7490ba2c393a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%gui wx\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "import os\n",
    "\n",
    "#####################\n",
    "# Import of utils.py functions\n",
    "#####################\n",
    "# Required to get utils.py and access its functions\n",
    "notebook_dir = os.path.abspath(\"\")\n",
    "parent_dir = os.path.abspath(os.path.join(notebook_dir, '..'))\n",
    "sys.path.append(parent_dir)\n",
    "sys.path.append('.')\n",
    "from utils import loadFSL, FSLeyesServer, mkdir_no_exist\n",
    "\n",
    "####################\n",
    "# DIPY_HOME should be set prior to import of dipy to make sure all downloads point to the right folder\n",
    "####################\n",
    "os.environ[\"DIPY_HOME\"] = \"/home/jovyan/Data\"\n",
    "#############################\n",
    "# Loading fsl and freesurfer within Neurodesk\n",
    "# You can find the list of available other modules by clicking on the \"Softwares\" tab on the left\n",
    "#############################\n",
    "import lmod\n",
    "await lmod.purge(force=True)\n",
    "await lmod.load('fsl/6.0.7.4')\n",
    "await lmod.load('freesurfer/7.4.1')\n",
    "await lmod.list()\n",
    "\n",
    "####################\n",
    "# Setup FSL path\n",
    "####################\n",
    "loadFSL()\n",
    "\n",
    "###################\n",
    "# Load all relevant libraries for the lab\n",
    "##################\n",
    "import fsl.wrappers\n",
    "from fsl.wrappers import fslmaths\n",
    "\n",
    "import nilearn\n",
    "#from nilearn.datasets import fetch_development_fmri\n",
    "\n",
    "import mne\n",
    "import mne_nirs\n",
    "import dipy\n",
    "#from dipy.data import fetch_bundles_2_subjects, read_bundles_2_subjects\n",
    "import xml.etree.ElementTree as ET\n",
    "import os.path as op\n",
    "import nibabel as nib\n",
    "import glob\n",
    "import subprocess\n",
    "import ants\n",
    "\n",
    "import openneuro\n",
    "from mne.datasets import sample\n",
    "from mne_bids import BIDSPath, read_raw_bids, print_dir_tree, make_report # not all used\n",
    "\n",
    "\n",
    "# Useful imports to define the direct download function below\n",
    "import requests\n",
    "import urllib.request\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "# FSL function wrappers which we will call from python directly\n",
    "from fsl.wrappers import fast, bet\n",
    "from fsl.wrappers.misc import fslroi\n",
    "from fsl.wrappers import flirt\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3dafa9c-8251-45c4-8395-77fc8eb8180e",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_dir = os.path.abspath(\"\")\n",
    "#print(f\"current_dir: {current_dir}\")\n",
    "sys.path.append(current_dir)\n",
    "\n",
    "dataset_id = 'ds000171'\n",
    "subjects = ['sub-control{:02d}'.format(i+1) for i in range(20)]\n",
    "\n",
    "dataset_path = os.path.join(current_dir, \"data\", dataset_id)\n",
    "deriv_path = os.path.join(current_dir,\"data\", \"derivatives\")\n",
    "preproc_path = os.path.join(deriv_path, 'preprocessed_data')\n",
    "\n",
    "subject = \"sub-control01\"\n",
    "task = 'music'\n",
    "mkdir_no_exist(dataset_path)\n",
    "mkdir_no_exist(preproc_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aade4da7-1157-443c-b6be-05fd1e7f2d21",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fsleyesDisplay = FSLeyesServer()\n",
    "fsleyesDisplay.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba14914-5a25-441f-8b26-cd3795cdabe2",
   "metadata": {},
   "source": [
    "### Overview of the brain before any preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8300fb2b-cadf-4a2d-a0e7-b64e53a0ea4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all paths from anatomical preprocessing\n",
    "anatomical_path = '/data/data/ds000171/sub-control01/anat/sub-control01_T1w.nii.gz'\n",
    "resulting_mask = '/data/data/derivatives/preprocessed_data/sub-control01/anat/sub-control01_T1w_mask.nii.gz'\n",
    "betted_brain_path = '/data/data/derivatives/preprocessed_data/sub-control01/anat/sub-control01_T1w.nii.gz'\n",
    "segmentation_path  = '/data/data/derivatives/preprocessed_data/sub-control01/anat/sub-control01_T1w_fast'\n",
    "mni_template = op.expandvars(op.join('$FSLDIR', 'data', 'standard', 'MNI152_T1_1mm_brain'))\n",
    "t1w_mni = '/data/data/derivatives/preprocessed_data/sub-control01/anat/sub-control01_T1w_mni_SyN.nii.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f7a45f0-2e82-4408-ac75-3d9823140ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "anatomical_path = op.join(dataset_path, subject, 'anat', '{}_T1w.nii.gz').format(subject)\n",
    "fsleyesDisplay.resetOverlays()\n",
    "fsleyesDisplay.load(anatomical_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "799fc6f1-8d98-4134-b584-26cc9977980b",
   "metadata": {},
   "source": [
    "# 1. Skull Removal and fast tissue segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce668b1-d3aa-48b0-b8e0-d03d773b3467",
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessed import get_skull_stripped_anatomical\n",
    "\n",
    "resulting_mask = get_skull_stripped_anatomical(dataset_path, preproc_path, subject, robust=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c60a04-d8fd-410c-9a67-4c179592ece8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fsleyesDisplay.resetOverlays()\n",
    "fsleyesDisplay.load(op.join(dataset_path, subject, 'anat', '{}_T1w.nii.gz').format(subject))\n",
    "fsleyesDisplay.load(resulting_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d43988-c127-423c-a097-cb9349e4a079",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The brain without skull is in the derivatives folder\n",
    "from preprocessed import apply_fsl_mask\n",
    "\n",
    "betted_brain_path = apply_fsl_mask(dataset_path, resulting_mask, preproc_path, subject)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f871464-8004-42c0-8575-47afc403e2a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fsleyesDisplay.resetOverlays()\n",
    "fsleyesDisplay.load(betted_brain_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96036c49-6463-42e4-bf63-75e76d3b8a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO discuss segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd5d506-f44e-4640-9449-ea3c035e6a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessed import apply_fast\n",
    "segmentation_path = apply_fast(preproc_path, subject)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b3c2f26-07d2-4076-bcdf-f74a3b6b0164",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fsleyesDisplay.resetOverlays()\n",
    "fsleyesDisplay.load(betted_brain_path)\n",
    "fsleyesDisplay.load(glob.glob(op.join(preproc_path, subject, 'anat','*pve_0*'))[0])\n",
    "fsleyesDisplay.load(glob.glob(op.join(preproc_path, subject, 'anat','*pve_1*'))[0])\n",
    "fsleyesDisplay.load(glob.glob(op.join(preproc_path, subject, 'anat','*pve_2*'))[0])\n",
    "fsleyesDisplay.displayCtx.getOpts(fsleyesDisplay.overlayList[1]).cmap = 'Red'\n",
    "fsleyesDisplay.displayCtx.getOpts(fsleyesDisplay.overlayList[2]).cmap = 'Green'\n",
    "fsleyesDisplay.displayCtx.getOpts(fsleyesDisplay.overlayList[3]).cmap = 'Blue'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a5e30be-f473-4abf-b7fd-2bcd497099c6",
   "metadata": {},
   "source": [
    "## Linear normalization using Ants\n",
    "Using advanced normalization tools (ANTS), we standardize the fMRI to a standard, to be able to do comparisons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ab00e4-fe40-4262-9d7b-00c097492f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca4e23d-4e50-401f-9f6d-f50f5af308a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessed import apply_ants\n",
    "mni_template = op.expandvars(op.join('$FSLDIR', 'data', 'standard', 'MNI152_T1_1mm_brain'))\n",
    "t1w_mni = apply_ants(preproc_path, subject, mni_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a696a3-73b8-43cf-a878-b58b76189f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "fsleyesDisplay.resetOverlays()\n",
    "fsleyesDisplay.load(mni_template)\n",
    "fsleyesDisplay.load(t1w_mni)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edd866d4-7e09-4a9c-9180-53bc11dcd890",
   "metadata": {},
   "source": [
    "## Field Stabilisation\n",
    "Field Stabilisation doesn't seem necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7061a573-d260-46d6-b422-4e9cf253b21b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import nibabel as nib\n",
    "\n",
    "plt.plot(nib.load(\"/data/data/ds000171/sub-control01/func/sub-control01_task-music_run-1_bold.nii.gz\").get_fdata().mean(axis=(0,1,2)))\n",
    "plt.xlabel('Time (volume)')\n",
    "plt.ylabel('Mean voxel intensity')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad986043-9dad-406b-95fd-b9eb556a9312",
   "metadata": {},
   "source": [
    "##### Quality control passed for anatomical preprocessing !"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b509d033-3daf-4c91-ab16-00be8bda3479",
   "metadata": {},
   "source": [
    "# fMRI Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae56692-2b1d-43d9-9513-1acf5a846a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "#paths for fMRI preprocessing\n",
    "all_runs = os.path.join(preproc_path, subject, 'func', '{}_task-{}_run-{}_bold'.format(subject, task, 'all'))\n",
    "path_moco_data = './data/derivatives/preprocessed_data/sub-control01/func/sub-control01_task-music_run-all_bold_moco.nii.gz'\n",
    "epi_reg_path = './data/derivatives/preprocessed_data/sub-control01/func/sub-control01_task-music_run-all_bold_anat-space_epi.nii.gz'\n",
    "splits_path = op.join(preproc_path, subject, 'func','splits')\n",
    "split_vols = sorted(glob.glob(op.join(splits_path, '*_bold_split*')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f586cabb-9e29-459e-a861-da7213ed4f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fsleyesDisplay.resetOverlays()\n",
    "fsleyesDisplay.load(output_path+'_smoothed-6mm')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b7cb070-6686-459f-a3fc-27b6263770b1",
   "metadata": {},
   "source": [
    "## Standardization and run concatenation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf29cce2-59d1-426b-8539-d66ba482849f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessed import concatenate_mri_runs\n",
    "\n",
    "all_runs = os.path.join(preproc_path, subject, 'func', '{}_task-{}_run-{}_bold.nii.gz'.format(subject, task, 'all'))\n",
    "concatenate_mri_runs(dataset_path, subject, task, all_runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c69fb8ac-fc66-4241-a6cf-151751bf8504",
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessed import plot_bold_data, plot_mean_voxel_intensity\n",
    "\n",
    "plot_bold_data(all_runs, timepoints=[30,150,250])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c1c82ca-4b84-41b2-a0be-09fa2577cde6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_mean_voxel_intensity(all_runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc0de61c-328b-405c-a47b-03cd8aa71b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fsleyesDisplay.resetOverlays()\n",
    "fsleyesDisplay.load(all_runs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c701fa91-150a-47f0-8e8b-4d4f974a00ee",
   "metadata": {},
   "source": [
    "## Motion correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d54217c6-8f50-4f30-beac-3917f3d9b8c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fsleyesDisplay.resetOverlays()\n",
    "fsleyesDisplay.load(path_moco_data)\n",
    "fsleyesDisplay.load(reference_moco)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc402bde-ab27-45a3-a453-bc70b6094063",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from preprocessed import apply_mcflirt\n",
    "task = 'music'\n",
    "run = 'all'\n",
    "path_moco_data, reference_moco = apply_mcflirt(preproc_path, preproc_path, subject, task, run) # twice preproc_path since we start from 'all'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e8fdcfc-6e2c-4a7a-8607-546442ba25fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are basically (if looking only along X translation) no frame displacement above 0.2mm!\n",
    "def load_mot_params_fsl_6_dof(path):\n",
    "    return pd.read_csv(path, sep='  ', header=None, \n",
    "            engine='python', names=['Rotation x', 'Rotation y', 'Rotation z','Translation x', 'Translation y', 'Translation z'])\n",
    "\n",
    "mot_params = load_mot_params_fsl_6_dof(op.join(preproc_path, subject, 'func', '{}_task-{}_run-{}_bold_moco.par'.format(subject, task, \"all\")))\n",
    "mot_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ffe7c13-ee32-4fd9-88ce-9523710a6480",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# write your code here to inspect quickly the translation on X :)\n",
    "#%matplotlib inline\n",
    "\n",
    "# Getting the translation is easy\n",
    "trans = mot_params[\"Translation x\"] + mot_params[\"Translation y\"] + mot_params[\"Translation z\"]\n",
    "# Now, we want a 0.2mm with respect to previous frame:\n",
    "disp = np.diff(trans)\n",
    "# Lastly, we can ask for displacements (in absolute value) above 0.2mm and plot it to be clear:\n",
    "threshold=0.2\n",
    "plt.plot(np.abs(disp))\n",
    "plt.hlines(threshold, 0, 370,colors='black', linestyles='dashed', label='FD threshold')\n",
    "plt.xlabel(\"Volumes\")\n",
    "plt.ylabel(\"Framewise translation displacement (mm)\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77300e1e-fbd1-4a08-8888-9c9f8f96ed96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_FD_power(mot_params):\n",
    "    framewise_diff = mot_params.diff().iloc[1:]\n",
    "\n",
    "    rot_params = framewise_diff[['Rotation x', 'Rotation y', 'Rotation z']]\n",
    "    # Estimating displacement on a 50mm radius sphere\n",
    "    # To know this one, we can remember the definition of the radian!\n",
    "    # Indeed, let the radian be theta, the arc length be s and the radius be r.\n",
    "    # Then theta = s / r\n",
    "    # We want to determine here s, for a sphere of 50mm radius and knowing theta. Easy enough!\n",
    "    \n",
    "    # Another way to think about it is through the line integral along the circle.\n",
    "    # Integrating from 0 to theta with radius 50 will give you, unsurprisingly, r0 theta.\n",
    "    converted_rots = rot_params*50\n",
    "    trans_params = framewise_diff[['Translation x', 'Translation y', 'Translation z']]\n",
    "    fd = converted_rots.abs().sum(axis=1) + trans_params.abs().sum(axis=1)\n",
    "    return fd\n",
    "\n",
    "fd = compute_FD_power(mot_params).to_numpy()\n",
    "\n",
    "threshold = np.quantile(fd,0.75) + 1.5*(np.quantile(fd,0.75) - np.quantile(fd,0.25))\n",
    "plt.plot(list(range(1, fd.size+1)), fd)\n",
    "plt.xlabel('Volume')\n",
    "plt.ylabel('FD displacement (mm)')\n",
    "plt.hlines(threshold, 0, 370,colors='black', linestyles='dashed', label='FD threshold')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94cb2d0e-94f1-49b6-8338-ccf4041738c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO manually correcting voxels outside of the brain that are active\n",
    "black_value = 0.0005\n",
    "#whole plane at time point 122\n",
    "# For now just discard that one"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af45961c-9c16-4032-b7f4-1a2b9b86da56",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Epi to anatomical coregistration (very lengthy - do not run => jump to slice timing and smoothing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c49d217c-e502-499a-91d5-3266c6816919",
   "metadata": {},
   "source": [
    "Checks for this part \n",
    "\n",
    "- Is the functional in the right orientation?\n",
    "- Are the ventricles correctly aligned?\n",
    "- Are the boundaries of the EPI more or less matching the anatomical?\n",
    "- Applying ONLY motion correction transformation to the first volume yields the expected alignement (so it should be aligned with the \\_moco volume.)\n",
    "- Applying motion correction + epi -> anat should be aligned to anatomical\n",
    "- Finally, applying motion correction + epi > anat + anat > standard should be aligned to the standard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba4ad06-dc6f-4d0a-a12b-fa2b007e56ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessed import apply_epi_reg\n",
    "epi_reg_path, reference_epi = apply_epi_reg(dataset_path, preproc_path, path_moco_data, subject, task, 'all')\n",
    "# We did the coregistration of the reference volume and get a transform, now we need to apply it to all volumes\n",
    "#Alternative: use mcflirt with the -meanvol option and then use the mean functional volume as input to  epi_reg."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b34cd02-4eae-43bd-ad2c-9219e2222236",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect here if transformations worked\n",
    "fsleyesDisplay.resetOverlays()\n",
    "fsleyesDisplay.load('./data/derivatives/preprocessed_data/sub-control01/func/sub-control01_task-music_run-all_bold_anat-space_epi_fast_wmseg.nii.gz')\n",
    "fsleyesDisplay.load('./data/derivatives/preprocessed_data/sub-control01/anat/sub-control01_T1w_fast_pve_2')\n",
    "fsleyesDisplay.displayCtx.getOpts(fsleyesDisplay.overlayList[1]).cmap = 'Red'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e73bc19b-a4ea-42e8-a4fa-d8faf983aa92",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check how the white matter of the EPI matches your anatomical's white matter provided you have sufficient resolution\n",
    "fsleyesDisplay.resetOverlays()\n",
    "fsleyesDisplay.load(betted_brain_path)\n",
    "fsleyesDisplay.load(epi_reg_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9413e630-2b3e-4723-9709-fc2feec6dad0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# apply the transformation to all volumes - does not work\n",
    "\"\"\"all_epi = epi_reg_path+'_4d'\n",
    "\n",
    "#This should work with one transform for all volumes but apparently he wants one mat file per volume\n",
    "result = subprocess.run(['applyxfm4D', path_moco_data, anatomical_path, all_epi,path_epi_transform]) #, '-userprefix', ''\n",
    "\n",
    "#Alternative that does not work neither\n",
    "subprocess.run(['flirt', '-in', path_moco_data, '-ref', anatomical_path,'-out', all_epi, '-init', path_epi_transform,'-applyxfm'])\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e233c2-4e69-4bec-8b27-a41876535155",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# We split the volumes to later apply epi_reg one by one\n",
    "path_epi_transform = op.join(preproc_path, subject, 'func/sub-control01_task-music_run-all_bold_anat-space_epi.mat')\n",
    "split_target = path_moco_data\n",
    "splits_path = op.join(preproc_path, subject, 'func','splits')\n",
    "mkdir_no_exist(splits_path)\n",
    "split_name = op.join(splits_path, 'sub-control01_task-music_run-all_bold_split')\n",
    "\n",
    "#subprocess.run(['fslsplit', split_target, split_name, '-t'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76917be9-50dd-4e32-9a12-321a2c92a089",
   "metadata": {},
   "source": [
    "#### Apply the trasnformation to each volume independently "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a66f5ab-13f3-46dc-958e-a1542144730d",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_vols = sorted(glob.glob(op.join(splits_path, '*_bold_split*')))\n",
    "splits_epi_path = op.join(preproc_path, subject, 'func','splits_epi')\n",
    "mkdir_no_exist(splits_epi_path)\n",
    "for i,split_vol in enumerate(split_vols[79:]): \n",
    "    split_nbr = split_vol.split('_')[-1].split('.')[0].split('split')[1]\n",
    "    out_vol= op.join(preproc_path, subject, 'func', 'splits_epi','sub-control01_task-music_run-all_bold_epi_vol' + split_nbr)\n",
    "    subprocess.run(['flirt', '-in', split_vol, '-ref', anatomical_path,'-out', out_vol,\n",
    "                        '-init', path_epi_transform,'-applyxfm'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "347063f0-e74b-47d1-b9c9-84ad42c9b8a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.system('rm -rf {}'.format(op.join(splits_path, '*_bold_split*')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f15465c-6685-4f2c-9bb5-dc3e0ed558dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "fsleyesDisplay.resetOverlays()\n",
    "fsleyesDisplay.load(split_vols[0])\n",
    "fsleyesDisplay.load(split_vols[10])\n",
    "fsleyesDisplay.load(split_vols[20])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a54cebbe-6279-4d72-8668-d1f4a046c720",
   "metadata": {},
   "source": [
    "#### Combining runs together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db7df97-515f-4a53-91a3-0868307be31e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessed import combine_runs\n",
    "combine_runs(preproc_path, splits_epi_path, subject)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25af2803-0c66-45a4-a9bf-5347b372bd06",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import progressbar\n",
    "import gc\n",
    "split_vols_epi = sorted(glob.glob(op.join(splits_epi_path, '*_bold_epi*')))\n",
    "\n",
    "first_vol = nib.load(split_vols_epi[0])\n",
    "v_shape = first_vol.get_fdata().shape\n",
    "'{}_task-{}_run-{}_bold_moco'\n",
    "filename = op.join(preproc_path, subject, 'func', 'sub-control01_task-music_run-all_bold_epi_concat.dat')\n",
    "large_array = np.memmap(filename, dtype=np.float64, mode='w+', shape=(v_shape[0],v_shape[1],v_shape[2], len(split_vols_epi)))\n",
    "\n",
    "batch_size = len(split_vols_epi)//4\n",
    "\n",
    "A = np.zeros((v_shape[0],v_shape[1],v_shape[2], batch_size))\n",
    "\n",
    "with progressbar.ProgressBar(max_value=len(split_vols_epi)) as bar:\n",
    "    for batch_i in range(4):\n",
    "        print('Starting for batch {}/4'.format(batch_i+1))\n",
    "        start_batch = batch_size * batch_i\n",
    "        end_batch = min(batch_size * (batch_i+1),len(split_vols_epi))\n",
    "        max_len = end_batch - start_batch + 1\n",
    "        for i in range(start_batch, end_batch):\n",
    "            vol = nib.load(split_vols_epi[i])\n",
    "            A[:,:,:,i-start_batch] = vol.get_fdata()\n",
    "            bar.update(i)\n",
    "        large_array[:,:,:, start_batch:end_batch] = A[:,:,:,:max_len]\n",
    "        gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "248c792f-e2a3-49c5-af7c-81453a40ad8f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#large_array.flush()\n",
    "#del large_array\n",
    "print(\"Done flushing mmap\")\n",
    "large_array = np.memmap(filename, dtype=np.float64, mode='r', shape=(v_shape[0],v_shape[1],v_shape[2], len(produced_vols)))\n",
    "\n",
    "# Step 2: Modify the header to indicate that we have 4D data, and specify its TR.\n",
    "header = first_vol.header.copy()  # Copy the header of the first volume (to get right resolution, affine, Q-form etc)\n",
    "header['dim'][0] = 4  # Specifies that this is a 4D dataset\n",
    "header['dim'][1:5] = large_array.shape  # Update dimensions (x, y, z, t)\n",
    "header['pixdim'][4] = 1.5  # Set the TR in the 4th dimension. You can see the TR of the data by looking at your original EPI series with fslhd, remember ;)\n",
    "print(\"Done with header\")\n",
    "\n",
    "# Step 3: Create the Nifti1 image and save it to disk\n",
    "mni_epi = op.join(preproc_root, 'sub-001', 'func', 'sub-001_task-sitrep_run-01_bold_mni.nii.gz')\n",
    "img = nib.Nifti1Image(large_array, first_vol.affine, first_vol.header)\n",
    "print(\"Done creating the image\")\n",
    "img.to_filename(mni_epi)\n",
    "print(\"Done writing it to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da0df95-ecff-425f-958f-07687f65b242",
   "metadata": {},
   "outputs": [],
   "source": [
    "fsleyesDisplay.resetOverlays()\n",
    "fsleyesDisplay.load(mni_template)\n",
    "fsleyesDisplay.load(split_vols_epi[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b5c140-2f9f-4c60-b5ec-c852deb76a4c",
   "metadata": {},
   "source": [
    "## Slice Time correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f4755f3-a9ea-4e19-b20e-859cb9efcc3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "task='music'\n",
    "data = pd.read_json(op.join(dataset_path, 'task-{}_bold.json'.format(task)), typ= 'series')\n",
    "slice_timing = data['SliceTiming']\n",
    "tr = data['RepetitionTime'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2029284-0bea-40b1-b5c6-1d2c6ddd2025",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# get the informations in the header - to determine the number of slices\n",
    "os.system('fslhd {}'.format(op.join(preproc_path, subject, 'func', 'sub-control01_task-music_run-all_bold_moco.nii.gz')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f847fa4d-7092-4d3d-80be-6ecb28c2c916",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The dimension on which the slides should have length ~', len(slice_timing)) #check which dimensions has the slices # here it is the z dimension so we give \"-d 3\" to slicetimer below "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9311a219-e67d-4b41-ba97-c3a0524e85a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "slice_order = np.argsort(slice_timing) + 1\n",
    "\n",
    "# Write to a file the corresponding sorted timings :)\n",
    "timing_path = op.join(preproc_path, subject, 'func', 'sub-001_task-music_run-1_slice-timings.txt')\n",
    "file = open(timing_path, mode='w')\n",
    "for t in slice_order:\n",
    "    file.write(str(t) + '\\n')\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eefaaa0-7c9c-4636-bc4d-f2db3a632ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_to_realign = op.join(preproc_path, subject, 'func', 'sub-control01_task-music_run-all_bold_moco.nii.gz')\n",
    "slice_corrected = op.join(preproc_path, subject, 'func', 'sub-control01_task-music_run-all_bold_slice-corr')\n",
    "\n",
    "subprocess.run(['slicetimer', '-i', file_to_realign, '-o', slice_corrected, '-r', str(tr), '-d', str(3), '--ocustom={}'.format(timing_path)]) #os.system('slicetimer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c7835ba-387a-4e67-aa66-eda4341ca8f8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fsleyesDisplay.resetOverlays()\n",
    "fsleyesDisplay.load(slice_corrected)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c207cc9b-173f-4c10-9b2a-5c13bea3cadb",
   "metadata": {},
   "source": [
    "## Smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a7de95-79e1-4717-987f-a27348eae3d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "mkdir_no_exist(op.join(preproc_path, subject, 'func', 'final'))\n",
    "smooth_voxel = 5 #mm\n",
    "output_path = op.join(preproc_path, subject, 'func', 'final','sub-control01_task-music_run-all_bold')\n",
    "subprocess.run(['fslmaths',path_moco_data, '-s', str(smooth_voxel/2.3548), '{}_smoothed-{}mm'.format(output_path, smooth_voxel)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e63a9e58-7a0c-4e21-8780-ceac4049029d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fsleyesDisplay.resetOverlays()\n",
    "fsleyesDisplay.load('./data/derivatives/preprocessed_data/sub-control01/func/final/sub-control01_task-music_run-all_bold_smoothed-5mm.nii.gz')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
