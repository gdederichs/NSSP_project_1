{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb3e06b-bfdb-469e-9b60-7490ba2c393a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%gui wx\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "import os\n",
    "\n",
    "#####################\n",
    "# Import of utils.py functions\n",
    "#####################\n",
    "# Required to get utils.py and access its functions\n",
    "notebook_dir = os.path.abspath(\"\")\n",
    "parent_dir = os.path.abspath(os.path.join(notebook_dir, '..'))\n",
    "sys.path.append(parent_dir)\n",
    "sys.path.append('.')\n",
    "from utils import loadFSL, FSLeyesServer, mkdir_no_exist\n",
    "\n",
    "####################\n",
    "# DIPY_HOME should be set prior to import of dipy to make sure all downloads point to the right folder\n",
    "####################\n",
    "os.environ[\"DIPY_HOME\"] = \"/home/jovyan/Data\"\n",
    "#############################\n",
    "# Loading fsl and freesurfer within Neurodesk\n",
    "# You can find the list of available other modules by clicking on the \"Softwares\" tab on the left\n",
    "#############################\n",
    "import lmod\n",
    "await lmod.purge(force=True)\n",
    "await lmod.load('fsl/6.0.7.4')\n",
    "await lmod.load('freesurfer/7.4.1')\n",
    "await lmod.list()\n",
    "\n",
    "####################\n",
    "# Setup FSL path\n",
    "####################\n",
    "loadFSL()\n",
    "\n",
    "###################\n",
    "# Load all relevant libraries for the lab\n",
    "##################\n",
    "import fsl.wrappers\n",
    "from fsl.wrappers import fslmaths\n",
    "\n",
    "import nilearn\n",
    "#from nilearn.datasets import fetch_development_fmri\n",
    "\n",
    "import mne\n",
    "import mne_nirs\n",
    "import dipy\n",
    "#from dipy.data import fetch_bundles_2_subjects, read_bundles_2_subjects\n",
    "import xml.etree.ElementTree as ET\n",
    "import os.path as op\n",
    "import nibabel as nib\n",
    "import glob\n",
    "\n",
    "import ants\n",
    "\n",
    "import openneuro\n",
    "from mne.datasets import sample\n",
    "from mne_bids import BIDSPath, read_raw_bids, print_dir_tree, make_report # not all used\n",
    "\n",
    "\n",
    "# Useful imports to define the direct download function below\n",
    "import requests\n",
    "import urllib.request\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "# FSL function wrappers which we will call from python directly\n",
    "from fsl.wrappers import fast, bet\n",
    "from fsl.wrappers.misc import fslroi\n",
    "from fsl.wrappers import flirt\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3dafa9c-8251-45c4-8395-77fc8eb8180e",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_dir = os.path.abspath(\"\")\n",
    "#print(f\"current_dir: {current_dir}\")\n",
    "sys.path.append(current_dir)\n",
    "\n",
    "dataset_id = 'ds000171'\n",
    "subjects = ['sub-control{:02d}'.format(i+1) for i in range(20)]\n",
    "\n",
    "dataset_path = os.path.join(current_dir, \"data\", dataset_id)\n",
    "deriv_path = os.path.join(current_dir,\"data\", \"derivatives\")\n",
    "preproc_path = os.path.join(deriv_path, 'preprocessed_data')\n",
    "\n",
    "subject = \"sub-control01\"\n",
    "\n",
    "mkdir_no_exist(dataset_path)\n",
    "mkdir_no_exist(preproc_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aade4da7-1157-443c-b6be-05fd1e7f2d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "fsleyesDisplay = FSLeyesServer()\n",
    "fsleyesDisplay.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba14914-5a25-441f-8b26-cd3795cdabe2",
   "metadata": {},
   "source": [
    "### Overview of the brain before any preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7a730449-ff15-4b07-976f-90c6b7585a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "anatomical_path = op.join(dataset_path, subject, 'anat', '{}_T1w.nii.gz').format(subject)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f7a45f0-2e82-4408-ac75-3d9823140ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fsleyesDisplay.resetOverlays()\n",
    "fsleyesDisplay.load(anatomical_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "799fc6f1-8d98-4134-b584-26cc9977980b",
   "metadata": {},
   "source": [
    "# 1. Skull Removal and fast tissue segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ce668b1-d3aa-48b0-b8e0-d03d773b3467",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with BET.\n"
     ]
    }
   ],
   "source": [
    "from preprocessed import get_skull_stripped_anatomical\n",
    "\n",
    "resulting_mask = get_skull_stripped_anatomical(dataset_path, preproc_path, subject, robust=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c60a04-d8fd-410c-9a67-4c179592ece8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fsleyesDisplay.resetOverlays()\n",
    "\n",
    "fsleyesDisplay.load(op.join(dataset_path, subject, 'anat', '{}_T1w.nii.gz').format(subject))\n",
    "fsleyesDisplay.load(resulting_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "81d43988-c127-423c-a097-cb9349e4a079",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The brain without skull is in the derivatives folder\n",
    "from preprocessed import apply_fsl_mask\n",
    "\n",
    "betted_brain_path = apply_fsl_mask(dataset_path, resulting_mask, preproc_path, subject)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f871464-8004-42c0-8575-47afc403e2a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fsleyesDisplay.resetOverlays()\n",
    "fsleyesDisplay.load(betted_brain_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96036c49-6463-42e4-bf63-75e76d3b8a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO discuss segmentation, not done because files not available - field map unwarping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dbd5d506-f44e-4640-9449-ea3c035e6a2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with fast\n"
     ]
    }
   ],
   "source": [
    "from preprocessed import apply_fast\n",
    "segmentation_path = apply_fast(preproc_path, subject)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b3c2f26-07d2-4076-bcdf-f74a3b6b0164",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fsleyesDisplay.resetOverlays()\n",
    "fsleyesDisplay.load(bet_path)\n",
    "fsleyesDisplay.load(glob.glob(op.join(preproc_path, subject, 'anat','*pve_0*'))[0])\n",
    "fsleyesDisplay.load(glob.glob(op.join(preproc_path, subject, 'anat','*pve_1*'))[0])\n",
    "fsleyesDisplay.load(glob.glob(op.join(preproc_path, subject, 'anat','*pve_2*'))[0])\n",
    "fsleyesDisplay.displayCtx.getOpts(fsleyesDisplay.overlayList[1]).cmap = 'Red'\n",
    "fsleyesDisplay.displayCtx.getOpts(fsleyesDisplay.overlayList[2]).cmap = 'Green'\n",
    "fsleyesDisplay.displayCtx.getOpts(fsleyesDisplay.overlayList[3]).cmap = 'Blue'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a5e30be-f473-4abf-b7fd-2bcd497099c6",
   "metadata": {},
   "source": [
    "## Linear normalization using Ants\n",
    "Using advanced normalization tools (ANTS), we standardize the fMRI to a standard, to be able to do comparisons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a6264714-4ce5-443c-b7d4-73377c1997c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "type_of_transform = 'SyN'\n",
    "subfolder='anat'\n",
    "target = op.join(preproc_path, '{}'.format(subject), 'anat', '{}_T1w'.format(subject))\n",
    "reference = op.expandvars(op.join('$FSLDIR', 'data', 'standard', 'MNI152_T1_1mm_brain'))\n",
    "moving_image = ants.image_read(target + '.nii.gz')\n",
    "fixed_image = ants.image_read(reference + '.nii.gz')\n",
    "\n",
    "    # Compute the transformation (non linear) to align the moving image to the fixed image\n",
    "transformation = ants.registration(fixed=fixed_image, moving=moving_image, type_of_transform = type_of_transform)\n",
    "\n",
    "    # After the transformation has been computed, apply it\n",
    "warpedImage = ants.apply_transforms(fixed=fixed_image, moving=moving_image, transformlist=transformation['fwdtransforms'])\n",
    "\n",
    "    # Save the image to disk\n",
    "resultAnts = op.join(preproc_path, subject, subfolder, '{}_T1w_mni_{}.nii.gz'.format(subject, type_of_transform))\n",
    "ants.image_write(warpedImage, resultAnts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4225b062-a9d3-4b4e-beb8-424066df4734",
   "metadata": {},
   "outputs": [],
   "source": [
    "mni_template = op.expandvars(op.join('$FSLDIR', 'data', 'standard', 'MNI152_T1_1mm_brain'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f5ab00e4-fe40-4262-9d7b-00c097492f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca4e23d-4e50-401f-9f6d-f50f5af308a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessed import apply_ants\n",
    "mni_template = op.expandvars(op.join('$FSLDIR', 'data', 'standard', 'MNI152_T1_1mm_brain'))\n",
    "resultAnts = apply_ants(preproc_path, subject, mni_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a696a3-73b8-43cf-a878-b58b76189f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "fsleyesDisplay.resetOverlays()\n",
    "fsleyesDisplay.load(mni_template)\n",
    "fsleyesDisplay.load(resultAnts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edd866d4-7e09-4a9c-9180-53bc11dcd890",
   "metadata": {},
   "source": [
    "## Field Stabilisation\n",
    "Field Stabilisation doesn't seem necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7061a573-d260-46d6-b422-4e9cf253b21b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import nibabel as nib\n",
    "\n",
    "plt.plot(nib.load(\"/data/data/ds000171/sub-control01/func/sub-control01_task-music_run-1_bold.nii.gz\").get_fdata().mean(axis=(0,1,2)))\n",
    "plt.xlabel('Time (volume)')\n",
    "plt.ylabel('Mean voxel intensity')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b509d033-3daf-4c91-ab16-00be8bda3479",
   "metadata": {},
   "source": [
    "# fMRI Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "9dcd5a82-01b0-46ab-aa0e-3c86675dcf7b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#standardize the runs and concatenate them together\n",
    "runs = []\n",
    "bids_root = dataset_path\n",
    "for i in range(3):\n",
    "    run = os.path.join(bids_root, subject, 'func', '{}_task-{}_run-{}_bold'.format(subject, task, i+1))\n",
    "    mean = run.replace('ds000171', 'derivatives/preprocessed_data') + '_mean' \n",
    "    std = run.replace('ds000171', 'derivatives/preprocessed_data') + '_std'\n",
    "    norm = run.replace('ds000171', 'derivatives/preprocessed_data') + '_norm'\n",
    "    subprocess.run(['fslmaths', run, '-Tmean', mean])\n",
    "    subprocess.run(['fslmaths', run, '-Tstd', std])\n",
    "    subprocess.run(['fslmaths', run, '-sub', mean, '-div', std, norm])\n",
    "    os.system('rm -rf {}'.format(op.join(preproc_path, subject, 'func', '*_mean*')))\n",
    "    os.system('rm -rf {}'.format(op.join(preproc_path, subject, 'func', '*_std*')))\n",
    "    runs.append(norm)\n",
    "    \n",
    "all_runs = os.path.join(preproc_path, subject, 'func', '{}_task-{}_run-{}_bold'.format(subject, task, 'all'))\n",
    "subprocess.run(['fslmerge', '-t', all_runs, runs[0], runs[1], runs[2]])\n",
    "os.system('rm -rf {}'.format(op.join(preproc_path, subject, 'func', '*_norm*')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c701fa91-150a-47f0-8e8b-4d4f974a00ee",
   "metadata": {},
   "source": [
    "## Motion correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc402bde-ab27-45a3-a453-bc70b6094063",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from preprocessed import apply_mcflirt\n",
    "task = 'music'\n",
    "run = 'all'\n",
    "path_moco_data, reference_moco = apply_mcflirt(preproc_path, preproc_path, subject, task, run) # twice preproc_path since we start from 'all'\n",
    "fsleyesDisplay.resetOverlays()\n",
    "fsleyesDisplay.load(path_moco_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af45961c-9c16-4032-b7f4-1a2b9b86da56",
   "metadata": {},
   "source": [
    "## Epi to anatomical coregistration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28781a31-4fd8-43d3-a477-c057b378c523",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODOOOOO reference_epi should be done on the moco one, ??? serie3 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4dcdf84-98e7-41b5-97b2-1204cd078d55",
   "metadata": {},
   "source": [
    "Improvements forum: I usually use mcflirt with the  -meanvol option and then use the mean functional volume as input to  epi_reg."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "aba4ad06-dc6f-4d0a-a12b-fa2b007e56ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FLIRT pre-alignment\n",
      "Running BBR\n",
      "0.297502 0.999221 -0.039210 -0.004466 0.000000 0.039258 0.999165 0.011356 0.000000 0.004017 -0.011523 0.999925 0.000000 -5.417383 9.646792 -0.993922 1.000000 \n",
      "Done with EPI to anatomical registration\n"
     ]
    }
   ],
   "source": [
    "from preprocessed import apply_epi_reg\n",
    "epi_reg_path, reference_epi = apply_epi_reg(dataset_path, preproc_path, path_moco_data, subject, task, run)\n",
    "# We did the coregistration of the reference volume and get a transform, now we need to apply it to all volumes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9b34cd02-4eae-43bd-ad2c-9219e2222236",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect here if transformations worked\n",
    "fsleyesDisplay.resetOverlays()\n",
    "fsleyesDisplay.load(betted_brain_path)\n",
    "fsleyesDisplay.load(epi_reg_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c49d217c-e502-499a-91d5-3266c6816919",
   "metadata": {},
   "source": [
    "Now, how do we *know* if the registration is good or bad?\n",
    "Well, there are several things to watch out for, but here are some main leads:\n",
    "- Is the functional in the right orientation?\n",
    "- Are the ventricles correctly aligned?\n",
    "- Are the boundaries of the EPI more or less matching the anatomical?\n",
    "\n",
    "➡️ You can also check how the white matter of the EPI matches your anatomical's white matter provided you have sufficient resolution\n",
    "\n",
    "Note: __fast__ files are there for vizualisation purposes (they delete them)\n",
    "\n",
    "Please ensure that:\n",
    "- [ ] Applying ONLY motion correction transformation to the first volume yields the expected alignement (so it should be aligned with the \\_moco volume.)\n",
    "- [ ] Applying motion correction + epi -> anat should be aligned to anatomical\n",
    "- [ ] Finally, applying motion correction + epi > anat + anat > standard should be aligned to the standard"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70b4cf34-aa5b-48b2-a06d-5696c8a5b2a3",
   "metadata": {},
   "source": [
    "Applying the transformation to a single volume is nice, but we should still need to know where the transformation was saved, to apply it to all other volumes of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "be3fbe05-696b-49d6-af6f-ffd815f25850",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_epi_transform = op.join(preproc_path, subject, 'func/sub-control01_task-music_run-1_bold_anat-space_epi.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "475b1408-f205-4044-8d27-7f801eaded02",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Usage: /opt/fsl-6.0.7.4/bin/applyxfm4D <input volume> <ref volume> <output volume> <transformation matrix file/dir>\n",
      "\n",
      "\t--interp, -interp <nearestneighbour (or nn), trilinear, spline, sinc (default)>\n",
      "\t--singlematrix, -singlematrix (flag option, do not provide an argument)\n",
      "\t--fourdigit, -fourdigit (flag option, do not provide an argument)\n",
      "\t--userprefix, -userprefix <prefix>\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "65280"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.system('applyxfm4D') #Usage: applyxfm4D <input volume> <ref volume> <output volume> <transformation matrix file/dir>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9413e630-2b3e-4723-9709-fc2feec6dad0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# apply the transformation to all volumes\n",
    "all_epi = epi_reg_path+'_4d'\n",
    "#This should work with one transform for all volumes but apparently he wants one mat file per volume\n",
    "#result = subprocess.run(['applyxfm4D', path_moco_data, anatomical_path, all_epi,path_epi_transform]) #, '-userprefix', ''\n",
    "\n",
    "#Alternative that does not work neither\n",
    "#subprocess.run(['flirt', '-in', path_moco_data, '-ref', anatomical_path,'-out', all_epi, '-init', path_epi_transform,'-applyxfm'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e8e233c2-4e69-4bec-8b27-a41876535155",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['fslsplit', '/data/data/derivatives/preprocessed_data/sub-control01/func/sub-control01_task-music_run-1_bold_moco', '/data/data/derivatives/preprocessed_data/sub-control01/func/splits/sub-control01_task-music_run-1_bold_split', '-t'], returncode=0)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We split the volumes and apply it one by one\n",
    "split_target = path_moco_data\n",
    "splits_path = op.join(preproc_path, subject, 'func','splits')\n",
    "mkdir_no_exist(splits_path)\n",
    "split_name = op.join(splits_path, 'sub-control01_task-music_run-1_bold_split')\n",
    "\n",
    "subprocess.run(['fslsplit', split_target, split_name, '-t'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "5a66f5ab-13f3-46dc-958e-a1542144730d",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_vols = sorted(glob.glob(op.join(splits_path, '*_bold_split*')))\n",
    "for i,split_vol in enumerate(split_vols): \n",
    "    split_nbr = split_vol.split('_')[-1].split('.')[0].split('split')[1]\n",
    "    out_vol= op.join(preproc_path, subject, 'func', 'splits_epi','sub-control01_task-music_run-1_bold_epi_vol' + split_nbr)\n",
    "    \n",
    "    subprocess.run(['flirt', '-in', split_vol, '-ref', anatomical_path,'-out', out_vol,\n",
    "                        '-init', path_epi_transform,'-applyxfm'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "52e0bb60-9019-4134-b93f-c2b38b7f0e54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.system('rm -rf {}'.format(op.join(preproc_path, subject, 'func', '*_bold_split*')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce68a5ad-79a0-4279-98e2-8acb374144ee",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## For looking up stuff only, don't run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c66fac4a-978c-4d49-8133-855746c83303",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fsl.wrappers import applywarp\n",
    "\n",
    "# We show this one when selecting the first EPI (volume 0000) \n",
    "target_epi = op.join(preproc_path, subject, 'func', '{}_task-sitrep_run-{}_bold_middle-vol'.format(subject, run))\n",
    "split_nbr = '0000'\n",
    "epi_moco = op.join(preproc_path, subject, 'func', subject+ '_task-music_run-1_bold_moco.mat/', 'MAT_' + split_nbr)\n",
    "\n",
    "# We will name its warp as split0000\n",
    "warp_name = op.join(preproc_path, subject, 'func', subject + '_split' + split_nbr + '_epi_2_std_warp')\n",
    "\n",
    "# Get the transformation matrix of this volume (this one is actually the unit matrix, \n",
    "# since this volume is the reference)\n",
    "#TODOOOOOOOOOOOOOOOO\n",
    "\n",
    "# -- Step 1: Combine the transformations, that is :\n",
    "#    EPI -> Motion correction -> Coregistration to anatomical -> Normalization to standard\n",
    "#    EPI -> Motion correction is given by the matrix in sub-001_task-sitrep_run-01_bold_moco.mat/MAT_{vol_nbr}, where {vol_nbr} is the volume number of the volume of interest\n",
    "#    EPI -> Coreg to anatomical, this is the _warp.nii.gz file in func/ folder\n",
    "\n",
    "\n",
    "#    Anatomical > Template is saved by flirt when doing the anatomical to template coregistration, in anat/ folder\n",
    "func_2_anat= op.join(preproc_path, subject, 'func', subject+ '_task-music_run-1_bold_anat-space_warp.nii.gz') # contains affine transformation from EPI to T1 sapce\n",
    "\n",
    "combine_all_transforms(ref, warp_name, True, epi_2_moco=None, epi_2_anat_warp=func_2_anat, anat_2_standard_warp=anat_2_mni_trans)\n",
    "out_vol= op.join(preproc_path, subject, 'func', subject+ '_task-music_run-1_bold_std_vol' + split_nbr)\n",
    "\n",
    "# -- Step 2: Apply the transformation to our EPI\n",
    "subprocess.run(['applywarp', '-i', target_epi, '-r', ref, '-o', out_vol, '-w', warp_name, '--abs', '--premat={}'.format(epi_moco)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "726aac8f-141e-4f19-a8a3-7565dfccb903",
   "metadata": {},
   "source": [
    "### 1.2.4 Applying the transformation to the entire timeseries at last - flirt does this on its own"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d126bebc-2239-40c2-8bda-5fee086ae365",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_target = original_epi\n",
    "split_name = op.join(preproc_path, 'sub-001', 'func', 'sub-001_task-sitrep_run-01_bold_split')\n",
    "\n",
    "subprocess.run(['fslsplit', split_target, split_name, '-t'])\n",
    "print_dir_tree(bids_root,max_depth=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05990653-c8d0-4a35-9d6f-35345ea80535",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's combine the different transforms EXCEPT motion correction!\n",
    "warp_name = op.join(preproc_path, 'sub-001', 'func', 'sub-001_epi_moco_2_std_warp')\n",
    "\n",
    "print(\"Starting to combine transforms...\")\n",
    "#combine_all_transforms(ref, warp_name,  True, epi_2_moco=None, epi_2_anat_warp=func_2_anat, anat_2_standard_warp=anat_2_mni_trans)\n",
    "print(\"Done, moving on to application of transforms...\")\n",
    "\n",
    "###########\n",
    "# Now apply transformation to all our volumes.\n",
    "# We will remember the volumes as well, to group them back afterwards.\n",
    "##########\n",
    "\n",
    "# Notice that we are sorting the volumes here! This is important, to make sure we don't get them in random order :)\n",
    "split_vols = sorted(glob.glob(op.join(preproc_path, subject, 'func', '*_bold_split*')))\n",
    "\n",
    "\n",
    "# Define a function that wraps subprocess.run()\n",
    "def run_subprocess(split_vol, vol_nbr):\n",
    "    \"\"\"\n",
    "    SAFETY GOGGLES ON\n",
    "    This function launches applywarp in parallel to reach complete result quicker\n",
    "\n",
    "    Parameters\n",
    "    -----------\n",
    "    split_vol: str\n",
    "        Path to the volume on which to apply the transformation\n",
    "    vol_nbr: str\n",
    "        Number of the volume in the timeserie. Useful to reorder volumes after the fact, since parallelisation does not honour order.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    out_vol: str\n",
    "        Path to the transformed volume\n",
    "    vol_nbr: str\n",
    "        Number of the volume in the timeserie. Useful to reorder volumes after the fact.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        split_nbr = split_vol.split('_')[-1].split('.')[0].split('split')[1]\n",
    "        epi_moco = op.join(preproc_path, 'sub-001', 'func', 'sub-001_task-sitrep_run-01_bold_moco.mat/', 'MAT_' + split_nbr)\n",
    "        out_vol= op.join(preproc_path, 'sub-001', 'func', 'sub-001_task-sitrep_run-01_bold_std_vol' + split_nbr)\n",
    "        result = subprocess.run(['applywarp', '-i', split_vol, '-r', ref, '-o', out_vol, '-w', warp_name, '--abs', '--premat={}'.format(epi_moco)], check=True)\n",
    "        return out_vol, vol_nbr\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        return f\"applywarp for volume '{split_vol}' failed with error: {e.stderr.decode('utf-8')}\"\n",
    "\n",
    "\n",
    "produced_vols = [None]*len(split_vols)\n",
    "# Initialize ThreadPoolExecutor and the progress bar\n",
    "with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "    # Use tqdm to wrap the futures\n",
    "    with tqdm(total=len(split_vols)) as progress:\n",
    "        # Launch subprocesses in parallel\n",
    "        futures = {executor.submit(run_subprocess, vol,i): vol for i,vol in enumerate(split_vols)}\n",
    "\n",
    "        # Process completed tasks\n",
    "        for future in concurrent.futures.as_completed(futures):\n",
    "            out_vol, vol_nbr = future.result()  # Get the result of the subprocess\n",
    "            produced_vols[vol_nbr] = out_vol\n",
    "            # Update the progress bar for each completed task\n",
    "            progress.update(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c207cc9b-173f-4c10-9b2a-5c13bea3cadb",
   "metadata": {},
   "source": [
    "## Smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "d5a7de95-79e1-4717-987f-a27348eae3d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['fslmaths', '/data/data/derivatives/preprocessed_data/sub-control01/func/sub-control01_task-music_run-all_bold_moco', '-s', '2.547987090198743', '/data/data/derivatives/preprocessed_data/sub-control01/func/final/sub-control01_task-music_run-all_bold_smoothed-6mm'], returncode=0)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mkdir_no_exist(op.join(preproc_path, subject, 'func', 'final'))\n",
    "output_path = op.join(preproc_path, subject, 'func', 'final','sub-control01_task-music_run-all_bold') \n",
    "subprocess.run(['fslmaths',path_moco_data, '-s', str(6/2.3548), '{}_smoothed-6mm'.format(output_path)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b5c140-2f9f-4c60-b5ec-c852deb76a4c",
   "metadata": {},
   "source": [
    "## Slice Time correction (a faire encore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bdb7f97-2456-488d-b253-aa85316df3fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Very big red box telling you that this part takes 1h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b5ffd1b-ed00-413f-87ef-2d6939cc938c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f4755f3-a9ea-4e19-b20e-859cb9efcc3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "task='music'\n",
    "data = pd.read_json(op.join(dataset_path, 'task-{}_bold.json'.format(task)), typ= 'series')\n",
    "slice_timing = data['SliceTiming']\n",
    "tr = data['RepetitionTime'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2029284-0bea-40b1-b5c6-1d2c6ddd2025",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the informations in the header -to determine the number of slices\n",
    "os.system('fslhd {}'.format(op.join(bids_root, 'sub-001', 'func', 'sub-001_task-sitrep_run-01_bold.nii.gz')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f847fa4d-7092-4d3d-80be-6ecb28c2c916",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(slice_timing) #check which dimensions has the slices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9311a219-e67d-4b41-ba97-c3a0524e85a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "slice_order = np.argsort(slice_timing) + 1\n",
    "\n",
    "# Write to a file the corresponding sorted timings :)\n",
    "timing_path = op.join(preproc_path,  'sub-001', 'func', 'sub-001_task-sitrep_run-01_slice-timings.txt')\n",
    "file = open(timing_path, mode='w')\n",
    "for t in slice_order:\n",
    "    file.write(str(t) + '\\n')\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eefaaa0-7c9c-4636-bc4d-f2db3a632ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_to_realign = op.join(bids_root, 'sub-001', 'func', 'sub-001_task-sitrep_run-01_bold')\n",
    "output_target = op.join(preproc_path, 'sub-001', 'func', 'sub-001_task-sitrep_run-01_bold_slice-corr')\n",
    "\n",
    "subprocess.run(['slicetimer', '-i', file_to_realign, '-o', output_target, '-r', str(tr), '-d', str(3), '--ocustom={}'.format(timing_path)])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
