{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb3e06b-bfdb-469e-9b60-7490ba2c393a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%gui wx\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "import os\n",
    "\n",
    "#####################\n",
    "# Import of utils.py functions\n",
    "#####################\n",
    "# Required to get utils.py and access its functions\n",
    "notebook_dir = os.path.abspath(\"\")\n",
    "parent_dir = os.path.abspath(os.path.join(notebook_dir, '..'))\n",
    "sys.path.append(parent_dir)\n",
    "sys.path.append('.')\n",
    "from utils import loadFSL, FSLeyesServer, mkdir_no_exist\n",
    "\n",
    "####################\n",
    "# DIPY_HOME should be set prior to import of dipy to make sure all downloads point to the right folder\n",
    "####################\n",
    "os.environ[\"DIPY_HOME\"] = \"/home/jovyan/Data\"\n",
    "#############################\n",
    "# Loading fsl and freesurfer within Neurodesk\n",
    "# You can find the list of available other modules by clicking on the \"Softwares\" tab on the left\n",
    "#############################\n",
    "import lmod\n",
    "await lmod.purge(force=True)\n",
    "await lmod.load('fsl/6.0.7.4')\n",
    "await lmod.load('freesurfer/7.4.1')\n",
    "await lmod.list()\n",
    "\n",
    "####################\n",
    "# Setup FSL path\n",
    "####################\n",
    "loadFSL()\n",
    "\n",
    "###################\n",
    "# Load all relevant libraries for the lab\n",
    "##################\n",
    "import fsl.wrappers\n",
    "from fsl.wrappers import fslmaths\n",
    "\n",
    "import nilearn\n",
    "#from nilearn.datasets import fetch_development_fmri\n",
    "\n",
    "import mne\n",
    "import mne_nirs\n",
    "import dipy\n",
    "#from dipy.data import fetch_bundles_2_subjects, read_bundles_2_subjects\n",
    "import xml.etree.ElementTree as ET\n",
    "import os.path as op\n",
    "import nibabel as nib\n",
    "import glob\n",
    "\n",
    "import ants\n",
    "\n",
    "import openneuro\n",
    "from mne.datasets import sample\n",
    "from mne_bids import BIDSPath, read_raw_bids, print_dir_tree, make_report # not all used\n",
    "\n",
    "\n",
    "# Useful imports to define the direct download function below\n",
    "import requests\n",
    "import urllib.request\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "# FSL function wrappers which we will call from python directly\n",
    "from fsl.wrappers import fast, bet\n",
    "from fsl.wrappers.misc import fslroi, fslnvols\n",
    "from fsl.wrappers import flirt\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3dafa9c-8251-45c4-8395-77fc8eb8180e",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_dir = os.path.abspath(\"\")\n",
    "print(f\"current_dir: {current_dir}\")\n",
    "sys.path.append(current_dir)\n",
    "\n",
    "dataset_id = 'ds000171'\n",
    "subjects = ['sub-control{:02d}'.format(i+1) for i in range(20)]\n",
    "\n",
    "dataset_path = os.path.join(current_dir, \"data\", dataset_id)\n",
    "deriv_path = os.path.join(current_dir,\"data\", \"derivatives\")\n",
    "preproc_path = os.path.join(deriv_path, 'preprocessed_data')\n",
    "\n",
    "subject = \"sub-control01\"\n",
    "\n",
    "mkdir_no_exist(dataset_path)\n",
    "mkdir_no_exist(preproc_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aade4da7-1157-443c-b6be-05fd1e7f2d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "fsleyesDisplay = FSLeyesServer()\n",
    "fsleyesDisplay.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba14914-5a25-441f-8b26-cd3795cdabe2",
   "metadata": {},
   "source": [
    "### Overview of the brain before any preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f7a45f0-2e82-4408-ac75-3d9823140ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fsleyesDisplay.resetOverlays()\n",
    "anatomical_path = op.join(dataset_path, subject, 'anat', '{}_T1w.nii.gz').format(subject)\n",
    "fsleyesDisplay.load(anatomical_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "799fc6f1-8d98-4134-b584-26cc9977980b",
   "metadata": {},
   "source": [
    "# 1. Skull Removal and fast tissue segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce668b1-d3aa-48b0-b8e0-d03d773b3467",
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessed import get_skull_stripped_anatomical\n",
    "\n",
    "resulting_mask = get_skull_stripped_anatomical(dataset_path, preproc_path, subject, robust=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c60a04-d8fd-410c-9a67-4c179592ece8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fsleyesDisplay.resetOverlays()\n",
    "\n",
    "fsleyesDisplay.load(op.join(dataset_path, subject, 'anat', '{}_T1w.nii.gz').format(subject))\n",
    "fsleyesDisplay.load(resulting_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d43988-c127-423c-a097-cb9349e4a079",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The brain without skull is in the derivatives folder\n",
    "from preprocessed import apply_fsl_mask\n",
    "\n",
    "betted_brain_path = apply_fsl_mask(dataset_path, resulting_mask, preproc_path, subject)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f871464-8004-42c0-8575-47afc403e2a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fsleyesDisplay.resetOverlays()\n",
    "fsleyesDisplay.load(betted_brain_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96036c49-6463-42e4-bf63-75e76d3b8a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO discuss segmentation, not done because files not available - field map unwarping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd5d506-f44e-4640-9449-ea3c035e6a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessed import apply_fast\n",
    "segmentation_path = apply_fast(preproc_path, subject)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb4e106-2ae8-4c97-b7fe-059250ca7a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "segmentation_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b3c2f26-07d2-4076-bcdf-f74a3b6b0164",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fsleyesDisplay.resetOverlays()\n",
    "fsleyesDisplay.load(bet_path)\n",
    "fsleyesDisplay.load(glob.glob(op.join(preproc_path, subject, 'anat','*pve_0*'))[0])\n",
    "fsleyesDisplay.load(glob.glob(op.join(preproc_path, subject, 'anat','*pve_1*'))[0])\n",
    "fsleyesDisplay.load(glob.glob(op.join(preproc_path, subject, 'anat','*pve_2*'))[0])\n",
    "fsleyesDisplay.displayCtx.getOpts(fsleyesDisplay.overlayList[1]).cmap = 'Red'\n",
    "fsleyesDisplay.displayCtx.getOpts(fsleyesDisplay.overlayList[2]).cmap = 'Green'\n",
    "fsleyesDisplay.displayCtx.getOpts(fsleyesDisplay.overlayList[3]).cmap = 'Blue'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a5e30be-f473-4abf-b7fd-2bcd497099c6",
   "metadata": {},
   "source": [
    "## Linear normalization using Ants\n",
    "Using advanced normalization tools (ANTS), we standardize the fMRI to a standard, to be able to do comparisons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6264714-4ce5-443c-b7d4-73377c1997c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "type_of_transform = 'SyN'\n",
    "subfolder='anat'\n",
    "target = op.join(preproc_path, '{}'.format(subject), 'anat', '{}_T1w'.format(subject))\n",
    "reference = op.expandvars(op.join('$FSLDIR', 'data', 'standard', 'MNI152_T1_1mm_brain'))\n",
    "moving_image = ants.image_read(target + '.nii.gz')\n",
    "fixed_image = ants.image_read(reference + '.nii.gz')\n",
    "\n",
    "    # Compute the transformation (non linear) to align the moving image to the fixed image\n",
    "transformation = ants.registration(fixed=fixed_image, moving=moving_image, type_of_transform = type_of_transform)\n",
    "\n",
    "    # After the transformation has been computed, apply it\n",
    "warpedImage = ants.apply_transforms(fixed=fixed_image, moving=moving_image, transformlist=transformation['fwdtransforms'])\n",
    "\n",
    "    # Save the image to disk\n",
    "resultAnts = op.join(preproc_path, subject, subfolder, '{}_T1w_mni_{}.nii.gz'.format(subject, type_of_transform))\n",
    "ants.image_write(warpedImage, resultAnts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ab00e4-fe40-4262-9d7b-00c097492f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca4e23d-4e50-401f-9f6d-f50f5af308a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessed import apply_ants\n",
    "mni_template = op.expandvars(op.join('$FSLDIR', 'data', 'standard', 'MNI152_T1_1mm_brain'))\n",
    "resultAnts = apply_ants(preproc_path, subject, mni_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a696a3-73b8-43cf-a878-b58b76189f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "fsleyesDisplay.resetOverlays()\n",
    "mni_template = op.expandvars(op.join('$FSLDIR', 'data', 'standard', 'MNI152_T1_1mm_brain'))\n",
    "fsleyesDisplay.load(mni_template)\n",
    "fsleyesDisplay.load(resultAnts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edd866d4-7e09-4a9c-9180-53bc11dcd890",
   "metadata": {},
   "source": [
    "## Field Stabilisation\n",
    "Field Stabilisation doesn't seem necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7061a573-d260-46d6-b422-4e9cf253b21b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import nibabel as nib\n",
    "\n",
    "plt.plot(nib.load(\"/data/data/ds000171/sub-control01/func/sub-control01_task-music_run-1_bold.nii.gz\").get_fdata().mean(axis=(0,1,2)))\n",
    "plt.xlabel('Time (volume)')\n",
    "plt.ylabel('Mean voxel intensity')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c701fa91-150a-47f0-8e8b-4d4f974a00ee",
   "metadata": {},
   "source": [
    "## Motion correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc402bde-ab27-45a3-a453-bc70b6094063",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from preprocessed import apply_mcflirt\n",
    "task = 'music'\n",
    "run = '1'\n",
    "path_moco_data, reference_epi = apply_mcflirt(dataset_path, preproc_path, subject, task, run)\n",
    "fsleyesDisplay.resetOverlays()\n",
    "fsleyesDisplay.load(path_moco_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af45961c-9c16-4032-b7f4-1a2b9b86da56",
   "metadata": {},
   "source": [
    "## Epi to anatomical coregistration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "115cde88-9a97-4122-aada-33e6499fbfee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "dwell_time = 0.000620007 #TODO FIND - either dwell time or Effective echo spacing \n",
    "#it should be in order of milliseconds (0.3 to 60ms is reasonable)\n",
    "\n",
    "epi_reg_path = op.join(preproc_path, 'sub-control01', 'func', 'sub-control01_task-music_run-1_bold_anat-space_epi')\n",
    "\n",
    "subprocess.run(['epi_reg','--epi={}'.format(reference_epi), \n",
    "                '--t1={}'.format(anatomical_path), # original t1w mri scan\n",
    "                '--t1brain={}'.format(betted_brain_path), # brain without skull\n",
    "                '--out={}'.format(epi_reg_path), # output file\n",
    "                '--wmseg={}'.format(op.join(preproc_path, 'sub-control01', 'anat', 'sub-control01_T1w_fast_pve_2')), #white matter segmentation (?? Maybe not needed)\n",
    "                '--echospacing={}'.format(dwell_time)])\n",
    "\n",
    "print(\"Done with EPI to anatomical registration\")\n",
    "# We did the coregistration of one reference volume and get a transform, now we need to apply it to all volumes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b34cd02-4eae-43bd-ad2c-9219e2222236",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect here with fsleyes, such as fsleyesDisplay.load(yourEpi) :)\n",
    "fsleyesDisplay.resetOverlays()\n",
    "fsleyesDisplay.load(betted_brain_path)\n",
    "fsleyesDisplay.load(epi_reg_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70b4cf34-aa5b-48b2-a06d-5696c8a5b2a3",
   "metadata": {},
   "source": [
    "Applying the transformation to a single volume is nice, but we should still need to know where the transformation was saved, to apply it to all other volumes of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4219cdbf-e146-4669-807a-e85b3b75d87e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print_dir_tree(preproc_path, max_depth = 3) # for fieldmap correction it ended with warp, now I think it is the .mat file since linear transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae759d4e-062b-4379-b268-88372abb919e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_all_transforms(reference_volume, warp_save_name, is_linear, epi_2_moco=None, epi_2_anat_warp=None, anat_2_standard_warp=None):\n",
    "    \"\"\"\n",
    "    Combines transformation BEFORE motion correction all the way to standard space transformation\n",
    "    The various transformation steps are optional. As such, the final warp to compute is based on \n",
    "    which transforms are provided.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    reference_volume: str\n",
    "        Reference volume. The end volume after all transformations have been applied, relevant for final resolution and field of view.\n",
    "    warp_save_name: str\n",
    "        Under which name to save the total warp\n",
    "    is_linear: bool\n",
    "        Whether the transformation is linear or non linear.\n",
    "    epi_2_moco: str\n",
    "        Transformation of the EPI volume to motion-correct it (located in the .mat/ folder of the EPI)\n",
    "    epi_2_anat_warp: str\n",
    "        Transformation of the EPI volume to the anatomical space, typically obtained by epi_reg. Assumed to include fieldmap correction and thus be non-linear.\n",
    "    anat_2_standard_warp: str\n",
    "        Transformation of the anatomical volume to standard space, such as the MNI152 space. Might be linear or non linear, which affects is_linear value accordingly.\n",
    "    \"\"\"\n",
    "    from fsl.wrappers import convertwarp\n",
    "    args_base = {'premat': epi_2_moco, 'warp1': epi_2_anat_warp}\n",
    "    if is_linear:\n",
    "        args_base['postmat'] = anat_2_standard_warp\n",
    "    else:\n",
    "        args_base['warp2'] = anat_2_standard_warp\n",
    "    args_filtered = {k: v for k, v in args_base.items() if v is not None}\n",
    "\n",
    "    convertwarp(warp_save_name, reference_volume, **args_filtered)\n",
    "    print(\"Done with warp conversion\")\n",
    "\n",
    "def apply_transform(reference_volume, target_volume, output_name, transform):\n",
    "    \"\"\"\n",
    "    Applies a warp field to a target volume and resamples to the space of the reference volume.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    reference_volume: str\n",
    "        The reference volume for the final interpolation, resampling and POV setting\n",
    "    target_volume: str\n",
    "        The target volume to which the warp should be applied\n",
    "    output_name: str\n",
    "        The filename under which to save the new transformed image\n",
    "    transform: str\n",
    "        The filename of the warp (assumed to be a .nii.gz file)\n",
    "\n",
    "    See also\n",
    "    --------\n",
    "    combine_all_transforms to see how to build a warp field\n",
    "    \"\"\"\n",
    "    from fsl.wrappers import applywarp\n",
    "    applywarp(target_volume,reference_volume, output_name, w=transform, rel=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6721307b-2361-4bcb-835d-7da8f8b61e38",
   "metadata": {},
   "source": [
    "Using these two functions should not be too hard now. Notice that in combine_all_transforms, setting any transform to None instead of the correct transform will skip the transform step in the total transformation. This way, you should be able to perform quality control. In particular, please ensure that:\n",
    "- [ ] Applying ONLY motion correction transformation to the first volume yields the expected alignement (so it should be aligned with the \\_moco volume.)\n",
    "- [ ] Applying motion correction + epi -> anat should be aligned to anatomical\n",
    "- [ ] Finally, applying motion correction + epi > anat + anat > standard should be aligned to the standard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a401ed-22d1-4255-bca6-3db8b9f0bda8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Yann \n",
    "# a partir de la j'ai pas trop adapté a notre data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf9bde5-db57-4cb2-b68f-4960c97677a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a49d04-f0df-4562-acb0-a457e8b351f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c2bb9b-1600-4879-96a4-7e358c52b012",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c66fac4a-978c-4d49-8133-855746c83303",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from fsl.wrappers import applywarp\n",
    "ref=mni_template\n",
    "\n",
    "# We show this one when selecting the first EPI (volume 0000)\n",
    "target_epi = op.join(preproc_root, 'sub-001', 'func', 'sub-001_task-sitrep_run-01_bold_first-vol')\n",
    "split_nbr = '0000'\n",
    "\n",
    "# We will name its warp as split0000\n",
    "warp_name = op.join(preproc_root, 'sub-001', 'func', 'sub-001_split' + split_nbr + '_epi_2_std_warp')\n",
    "\n",
    "# Get the transformation matrix of this volume (this one is actually the unit matrix, \n",
    "# since this volume is the reference)\n",
    "\n",
    "\n",
    "# -- Step 1: Combine the transformations, that is : \n",
    "# EPI -> Motion correction -> Coregistration to anatomical -> Normalization to standard\n",
    "#    EPI -> Motion correction is given by the matrix in sub-001_task-sitrep_run-01_bold_moco.mat/MAT_{vol_nbr}, where {vol_nbr} is the volume number of the volume of interest\n",
    "#    EPI -> Coreg to anatomical, this is the _warp.nii.gz file in func/ folder\n",
    "\n",
    "#    Anatomical > Template is saved by flirt when doing the anatomical to template coregistration, in anat/ folder\n",
    "func_2_anat= op.join(preproc_root, 'sub-001', 'func', 'sub-001_task-sitrep_run-01_bold_anat-space_warp.nii.gz')\n",
    "epi_moco = op.join(preproc_root, 'sub-001', 'func', 'sub-001_task-sitrep_run-01_bold_moco.mat/', 'MAT_' + split_nbr)\n",
    "\n",
    "s0 = time.time()\n",
    "combine_all_transforms(ref, warp_name, True, epi_2_moco=epi_moco, epi_2_anat_warp=func_2_anat, anat_2_standard_warp=anat_2_mni_trans)# )\n",
    "s1 = time.time()\n",
    "print('Transform combination time:', s1 - s0)\n",
    "\n",
    "out_vol= op.join(preproc_root, 'sub-001', 'func', 'sub-001_task-sitrep_run-01_bold_std_vol' + split_nbr)\n",
    "\n",
    "# -- Step 2: Apply the transformation to our EPI\n",
    "applywarp(target_epi,ref, out_vol, w=warp_name, rel=False)\n",
    "s2 = time.time()\n",
    "print('Apply transform time:', s2 - s1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f244029c-ea27-4d9b-a336-a09c52ed1d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the optimized version\n",
    "combine_all_transforms(ref, warp_name,  True, epi_2_moco=None, epi_2_anat_warp=func_2_anat, anat_2_standard_warp=anat_2_mni_trans)\n",
    "\n",
    "out_vol= op.join(preproc_root, 'sub-001', 'func', 'sub-001_task-sitrep_run-01_bold_std_vol' + split_nbr + '_v2')\n",
    "subprocess.run(['applywarp', '-i', target_epi, '-r', ref, '-o', out_vol, '-w', warp_name, '--abs', '--premat={}'.format(epi_moco)])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "726aac8f-141e-4f19-a8a3-7565dfccb903",
   "metadata": {},
   "source": [
    "### 1.2.4 Applying the transformation to the entire timeseries at last"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d126bebc-2239-40c2-8bda-5fee086ae365",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_target = original_epi\n",
    "split_name = op.join(preproc_root, 'sub-001', 'func', 'sub-001_task-sitrep_run-01_bold_split')\n",
    "\n",
    "subprocess.run(['fslsplit', split_target, split_name, '-t'])\n",
    "print_dir_tree(bids_root,max_depth=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05990653-c8d0-4a35-9d6f-35345ea80535",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's combine the different transforms EXCEPT motion correction!\n",
    "warp_name = op.join(preproc_root, 'sub-001', 'func', 'sub-001_epi_moco_2_std_warp')\n",
    "\n",
    "print(\"Starting to combine transforms...\")\n",
    "combine_all_transforms(ref, warp_name,  True, epi_2_moco=None, epi_2_anat_warp=func_2_anat, anat_2_standard_warp=anat_2_mni_trans)\n",
    "print(\"Done, moving on to application of transforms...\")\n",
    "\n",
    "###########\n",
    "# Now apply transformation to all our volumes.\n",
    "# We will remember the volumes as well, to group them back afterwards.\n",
    "##########\n",
    "\n",
    "# Notice that we are sorting the volumes here! This is important, to make sure we don't get them in random order :)\n",
    "split_vols = sorted(glob.glob(op.join(preproc_root, 'sub-001', 'func', '*_bold_split*')))\n",
    "\n",
    "\n",
    "# Define a function that wraps subprocess.run()\n",
    "def run_subprocess(split_vol, vol_nbr):\n",
    "    \"\"\"\n",
    "    SAFETY GOGGLES ON\n",
    "    This function launches applywarp in parallel to reach complete result quicker\n",
    "\n",
    "    Parameters\n",
    "    -----------\n",
    "    split_vol: str\n",
    "        Path to the volume on which to apply the transformation\n",
    "    vol_nbr: str\n",
    "        Number of the volume in the timeserie. Useful to reorder volumes after the fact, since parallelisation does not honour order.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    out_vol: str\n",
    "        Path to the transformed volume\n",
    "    vol_nbr: str\n",
    "        Number of the volume in the timeserie. Useful to reorder volumes after the fact.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        split_nbr = split_vol.split('_')[-1].split('.')[0].split('split')[1]\n",
    "        epi_moco = op.join(preproc_root, 'sub-001', 'func', 'sub-001_task-sitrep_run-01_bold_moco.mat/', 'MAT_' + split_nbr)\n",
    "        out_vol= op.join(preproc_root, 'sub-001', 'func', 'sub-001_task-sitrep_run-01_bold_std_vol' + split_nbr)\n",
    "        result = subprocess.run(['applywarp', '-i', split_vol, '-r', ref, '-o', out_vol, '-w', warp_name, '--abs', '--premat={}'.format(epi_moco)], check=True)\n",
    "        return out_vol, vol_nbr\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        return f\"applywarp for volume '{split_vol}' failed with error: {e.stderr.decode('utf-8')}\"\n",
    "\n",
    "\n",
    "produced_vols = [None]*len(split_vols)\n",
    "# Initialize ThreadPoolExecutor and the progress bar\n",
    "with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "    # Use tqdm to wrap the futures\n",
    "    with tqdm(total=len(split_vols)) as progress:\n",
    "        # Launch subprocesses in parallel\n",
    "        futures = {executor.submit(run_subprocess, vol,i): vol for i,vol in enumerate(split_vols)}\n",
    "\n",
    "        # Process completed tasks\n",
    "        for future in concurrent.futures.as_completed(futures):\n",
    "            out_vol, vol_nbr = future.result()  # Get the result of the subprocess\n",
    "            produced_vols[vol_nbr] = out_vol\n",
    "            # Update the progress bar for each completed task\n",
    "            progress.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bdb7f97-2456-488d-b253-aa85316df3fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Very big red box telling you that this part takes 1h"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b5c140-2f9f-4c60-b5ec-c852deb76a4c",
   "metadata": {},
   "source": [
    "## Slice Time correction (a retravailler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b5ffd1b-ed00-413f-87ef-2d6939cc938c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f4755f3-a9ea-4e19-b20e-859cb9efcc3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "task='music'\n",
    "data = pd.read_json(op.join(dataset_path, 'task-{}_bold.json'.format(task)), typ= 'series')\n",
    "slice_timing = data['SliceTiming']\n",
    "tr = data['RepetitionTime'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2029284-0bea-40b1-b5c6-1d2c6ddd2025",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the informations in the header -to determine the number of slices\n",
    "os.system('fslhd {}'.format(op.join(bids_root, 'sub-001', 'func', 'sub-001_task-sitrep_run-01_bold.nii.gz')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f847fa4d-7092-4d3d-80be-6ecb28c2c916",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(slice_timing) #check which dimensions has the slices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9311a219-e67d-4b41-ba97-c3a0524e85a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "slice_order = np.argsort(slice_timing) + 1\n",
    "\n",
    "# Write to a file the corresponding sorted timings :)\n",
    "timing_path = op.join(preproc_root,  'sub-001', 'func', 'sub-001_task-sitrep_run-01_slice-timings.txt')\n",
    "file = open(timing_path, mode='w')\n",
    "for t in slice_order:\n",
    "    file.write(str(t) + '\\n')\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eefaaa0-7c9c-4636-bc4d-f2db3a632ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_to_realign = op.join(bids_root, 'sub-001', 'func', 'sub-001_task-sitrep_run-01_bold')\n",
    "output_target = op.join(preproc_root, 'sub-001', 'func', 'sub-001_task-sitrep_run-01_bold_slice-corr')\n",
    "\n",
    "subprocess.run(['slicetimer', '-i', file_to_realign, '-o', output_target, '-r', str(tr), '-d', str(3), '--ocustom={}'.format(timing_path)])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
